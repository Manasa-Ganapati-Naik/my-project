{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2e15c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3c2d470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id                                               name  \\\n",
      "0  12532561  Jessica OLSEN, on behalf of herself and all ot...   \n",
      "1  12532560  AMERICAN CENTER FOR LAW AND JUSTICE, Plaintiff...   \n",
      "2  12532562  UNITED STATES of America, Plaintiff, v. Steven...   \n",
      "3  12532563  Kaori STEARNEY, et al., Plaintiffs, v. UNITED ...   \n",
      "4  12532564  IN RE: GERMAN AUTOMOTIVE MANUFACTURERS ANTITRU...   \n",
      "\n",
      "                                   name_abbreviation decision_date  \\\n",
      "0                              Olsen v. Nelnet, Inc.    2019-05-21   \n",
      "1  Am. Ctr. for Law & Justice v. U.S. Dep't of Ju...    2019-06-30   \n",
      "2                             United States v. Emery    2019-06-21   \n",
      "3                          Stearney v. United States    2019-05-16   \n",
      "4          In re German Auto. Mfrs. Antitrust Litig.    2019-06-17   \n",
      "\n",
      "                    docket_number court/name_abbreviation  \n",
      "0                    4:18-CV-3081                 D. Neb.  \n",
      "1  Civil Action No. 16-2188 (TJK)                  D.D.C.  \n",
      "2               3:18-CR-30122-RAL                 D. S.D.  \n",
      "3           No. CV16-8060-PCT-DGC                D. Ariz.  \n",
      "4          MDL No. 2796 CRB (JSC)               N.D. Cal.  \n"
     ]
    }
   ],
   "source": [
    "path=\"C:/Users/manas/my-project/cleaned_legal_metadata.csv\"\n",
    "df=pd.read_csv(path)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a561acda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id                                               name  \\\n",
      "84  12532643  WORLD WATER WORKS HOLDINGS, INC., Plaintiff, v...   \n",
      "85  12532644  Caitlin BERNARD M.D., Plaintiff, v. INDIVIDUAL...   \n",
      "86  12532645  REXING QUALITY EGGS, Plaintiff, v. REMBRANDT E...   \n",
      "87  12532646  Osha JOSEPH, Plaintiff, v. Sgt. Bobby DONAHUE,...   \n",
      "88  12532647  ZURICH AMERICAN INSURANCE COMPANY, Plaintiff, ...   \n",
      "\n",
      "                                    name_abbreviation decision_date  \\\n",
      "84  World Water Works Holdings, Inc. v. Cont'l Cas...    2019-06-24   \n",
      "85  Bernard v. Individual Members of the Ind. Med....    2019-06-28   \n",
      "86                    Eggs v. Rembrandt Enters., Inc.    2019-05-29   \n",
      "87                                  Joseph v. Donahue    2019-05-28   \n",
      "88          Zurich Am. Ins. Co. v. Ins. Co. of N. Am.    2019-05-21   \n",
      "\n",
      "                docket_number court/name_abbreviation  \n",
      "84             No. 17 CV 5237               N.D. Ill.  \n",
      "85  No. 1:19-cv-01660-SEB-DML               S.D. Ind.  \n",
      "86  No. 3:19-cv-00031-JMS-MPB               S.D. Ind.  \n",
      "87  Civil No. 17-4712 ADM/SER                D. Minn.  \n",
      "88  Case No. 4:14 CV 1112 CDP                E.D. Mo.  \n"
     ]
    }
   ],
   "source": [
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72b8bd98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'name', 'name_abbreviation', 'decision_date', 'docket_number',\n",
      "       'court/name_abbreviation'],\n",
      "      dtype='object')\n",
      "id                         0\n",
      "name                       0\n",
      "name_abbreviation          0\n",
      "decision_date              0\n",
      "docket_number              0\n",
      "court/name_abbreviation    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61364dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89, 6)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a9bb201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                          int64\n",
      "name                       object\n",
      "name_abbreviation          object\n",
      "decision_date              object\n",
      "docket_number              object\n",
      "court/name_abbreviation    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46d7ab35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       D. Neb.\n",
       "1        D.D.C.\n",
       "2       D. S.D.\n",
       "3      D. Ariz.\n",
       "4     N.D. Cal.\n",
       "        ...    \n",
       "84    N.D. Ill.\n",
       "85    S.D. Ind.\n",
       "86    S.D. Ind.\n",
       "87     D. Minn.\n",
       "88     E.D. Mo.\n",
       "Name: court/name_abbreviation, Length: 89, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7373a3dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.900000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.253260e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.583602e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.253256e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.253258e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.253260e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.253262e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.253265e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id\n",
       "count  8.900000e+01\n",
       "mean   1.253260e+07\n",
       "std    2.583602e+01\n",
       "min    1.253256e+07\n",
       "25%    1.253258e+07\n",
       "50%    1.253260e+07\n",
       "75%    1.253262e+07\n",
       "max    1.253265e+07"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c145ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Civil       0.65      1.00      0.79        11\n",
      "    Criminal       1.00      0.20      0.33         5\n",
      "       Other       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.67        18\n",
      "   macro avg       0.55      0.40      0.37        18\n",
      "weighted avg       0.67      0.67      0.57        18\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\manas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\manas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load your CSV file\n",
    "df = pd.read_csv(\"cleaned_legal_metadata.csv\")\n",
    "\n",
    "# Step 1: Derive 'case_type' from 'docket_number'\n",
    "def extract_case_type(docket):\n",
    "    docket = str(docket).upper()\n",
    "    if 'CR' in docket:\n",
    "        return 'Criminal'\n",
    "    elif 'CV' in docket or 'CIVIL' in docket:\n",
    "        return 'Civil'\n",
    "    elif 'MDL' in docket:\n",
    "        return 'MDL'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "df['case_type'] = df['docket_number'].apply(extract_case_type)\n",
    "\n",
    "# Step 2: Prepare text features and labels\n",
    "X_text = df['name'].astype(str)\n",
    "y = df['case_type']\n",
    "\n",
    "# Step 3: Convert text to TF-IDF features\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X = vectorizer.fit_transform(X_text)\n",
    "\n",
    "# Step 4: Split into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Step 5: Train Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 6: Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3404d090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Civil       0.75      1.00      0.86        12\n",
      "    Criminal       1.00      0.25      0.40         4\n",
      "       Other       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.78        18\n",
      "   macro avg       0.92      0.58      0.64        18\n",
      "weighted avg       0.83      0.78      0.73        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"cleaned_legal_metadata.csv\")\n",
    "\n",
    "# Extract case type from docket number\n",
    "def extract_case_type(docket):\n",
    "    docket = str(docket).upper()\n",
    "    if 'CR' in docket:\n",
    "        return 'Criminal'\n",
    "    elif 'CV' in docket or 'CIVIL' in docket:\n",
    "        return 'Civil'\n",
    "    elif 'MDL' in docket:\n",
    "        return 'MDL'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "df['case_type'] = df['docket_number'].apply(extract_case_type)\n",
    "\n",
    "# Focus on major classes only\n",
    "df = df[df['case_type'].isin(['Civil', 'Criminal', 'Other'])]\n",
    "\n",
    "# Prepare features and labels\n",
    "X_text = df['name'].astype(str)\n",
    "y = df['case_type']\n",
    "\n",
    "# Vectorize case name text\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X = vectorizer.fit_transform(X_text)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = rf_model.predict(X_test)\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
